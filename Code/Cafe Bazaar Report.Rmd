---
title: "Cafe Bazaar Report"
author: "Mohammad Mazraeh"
date: "May 14, 2016"
output: html_document
---
# Synposis
In this research we want to analyse user payment data and cluster users in order to plan for promotions or solutions to make more money (Increase users long term value)!
User Segmentation Analysis and recommendations are usually done in two ways:
<li>Find Hot Products in a group and recommend it to users </li>
<li>Recommend most probable interesting products to each user</li>

In this research we will build both of recommendation system models. First method is done by finding top products in a particular group and recommend it to other groups. Second method is done using User Based Collaborative Filtering (UBCF) technique.
```{r,echo=FALSE,warning=FALSE}
suppressMessages(library(dplyr, warn.conflicts = FALSE, quietly=TRUE))
suppressMessages(library(ggplot2, warn.conflicts = FALSE, quietly=TRUE))
suppressMessages(library(grid, warn.conflicts = FALSE, quietly=TRUE))
suppressMessages(library("data.table",warn.conflicts = FALSE, quietly=TRUE))
suppressMessages(library("recommenderlab",warn.conflicts = FALSE, quietly=TRUE))
```
# Data Processing
<p>In this part first we generate some raw data and then in cleaning phase convert it to useful features to do our analysis.
</p>
### Getting Data
<p>In this part we would simulate some data as input for our analysis. We use some parameters to generate data. The parameters are:</p>
<p>
<li>_**n**_ is number of data to generate.</li>
<li>_**numUsers**_ is the number of users.</li>
<li>_**typeFactor**_ is a factor including software types. in this analysis it's App or Game.</li>
<li>_**appCount**_: Number of apps in cafe bazaar.</li>
</p>
```{r}
n <- 1000000
numUsers <- 10000
appCount <- 100
typeFactor <- as.factor(1:10)
# Set seed for reproducability
set.seed(789)
```
<p>We assume the raw data table would have one ID and 4 features:</br>
_**userID**_: unique user ID.</br>
_**cat**_:  the payment was for an Application or a Game</br>
_**appID**_: A unique ID for each app </br>
_**amount**_:  the amount of payment</br>
_**payDate**_:  payment date</br>
</p>
<p>
It is assumed that installations with no payment are recorderd as _amount_ = 0.
Also any payment (including in-app purchases) is recorderd in the table.
</p>
<p>
To generate dataset we followed these steps: </br>
For each record _userID_ is sampled from user IDs. _cat_ is app category._appID_ is a unique ID for each app which have been sampled randomly. for _amount_ variable 0.9 of records will have zero value (Installations with no payment) and others are assumed to be from a normal distribution with arbitary mean and std. at last _payDate_ is sampled randomly between "2013/01/01" and "2016/01/01".
</p>
```{r}
payments <- 
      data.table(userID = sample(1:numUsers,size = n,replace = TRUE),
                 cat = sample(typeFactor,
                              replace = TRUE, 
                              prob = c(0.2,0.15,0.1,0.05,0.25,0.1,0.05,0.02,0.05,0.03)),
                 appID = sample(1:appCount,replace = TRUE),
                 amount = round(sample(c(abs(rnorm(n = 0.1*n,
                                                   mean = 3000,sd = 2000)),
                                         rep(0,0.9*n))),-2),
                 payDate = sample(seq(
                       as.Date('2013/01/01'), 
                       as.Date('2016/01/01'), 
                       by="day"), n,replace = TRUE))
```
Next we create a rating matrix. in _ratings_ matrix each row corresponds to a user and each column corresponds to an app. Thus _ratings_ matrix is an `r numUsers` * `r appCount` matrix. 0.9 of ratings are set to zero (and then replaced by NaN) which means user have not rated the apps.
```{r}
# Ratings Matrix is Filled Randomly. 
ratings = matrix(sample(0:5,numUsers*appCount,
                        replace = TRUE,
                        prob = c(0.9,0.02,0.02,0.02,0.02,0.02)),
                 nrow = numUsers)
ratings[ratings==0] <- NaN
```
### Preprocess Data
<p>
One of the most useful techniques to analyse user purchase history is to use RFM Models. R,F and M stand for Recency,Frequency and Monetary respectively. In this part we want to convert our input data into RFM Features:  
<li>_**FirstPurchaseDate**_: Roughly shows how long the user is with us.</li>
<li>_**LastPurchaseDate**_: basis of Recency.</li>
<li>_**Numberofpayments**_: basis of Frequency.</li>
<li>_**CatCount**_: basis of breadth (Number of unique categories which user is involved)</li>
<li>_**TotalAmount**_: basis of Monetary.</li>
</p>
```{r}
# Building RFM Features
RFM <- payments  %>% 
      group_by(userID)  %>% 
      summarise(FirstPurchaseDate = min(payDate),
                LastPurchaseDate = max(payDate),
                NumberPayments = sum(amount > 0),
                NumberofApps = length(unique(appID)),
                Breadth = length(unique(cat)),
                TotalAmount = sum(amount))


LastDate <- max(RFM$LastPurchaseDate)
RFM <- RFM %>% mutate(R = as.numeric(LastDate-LastPurchaseDate),
                      PayRatio = NumberPayments / NumberofApps)

```
# Analysis
<p>
In this part we do the main part of report. First we look at data to get familliar with the fields and distributions. After that we do a simple user segmentation according to conventional RFM features and develop a simple topN recommender system to recommend 10 apps for some clusters.
Finally we develope a per-user recommendation system using collaborative filtering.</br>
</p>
### Exploratory Data Analysis 
<p>Like any other data analysis after getting and cleaning data we should do some exploratory data analysis to get familiar with data and hopefully it gives good information and clues to continue the research. Let's have each features histogram and discuss it:</p>
```{r,echo=FALSE,warning=FALSE}
PlotRecency <- ggplot(RFM, aes(R %/% 7)) + geom_histogram(binwidth = 3) 
PlotRecency <- PlotRecency + labs(x = 'Recency(Weeks Ago)' , y = 'Count', title = 'Recency')

PlotFreq <- ggplot(RFM, aes(NumberPayments)) + geom_histogram(binwidth = 1)
PlotFreq <- PlotFreq + labs(x = 'Number of payments' , y = 'Count', title = 'Frequency')

PlotMonetary <- ggplot(RFM, aes(TotalAmount)) + geom_histogram(binwidth = 1000)
PlotMonetary <- PlotMonetary  + labs(x = 'Total Amount (Tomans)' , y = 'Count', title = 'Total Payement(Monetary)')

PlotNumApp <- ggplot(RFM,aes(NumberofApps)) + geom_histogram(binwidth = 5)
PlotNumApp <- PlotNumApp + labs(x = 'Number of Installed Apps', y = 'Count', title = 'Installed Apps')

PlotTenure <- ggplot(RFM, aes(as.numeric(LastDate - FirstPurchaseDate) %/% 7)) + geom_histogram(binwidth = 1)
PlotTenure <- PlotTenure + labs(x = 'First payment (Weeks Ago)' , y = 'Count', title = 'Tenure')

grid.newpage()
pushViewport(viewport(layout = grid.layout(3, 2)))
print(PlotRecency, vp = viewport(layout.pos.row = 1,layout.pos.col = 1))
print(PlotTenure, vp = viewport(layout.pos.row = 1,layout.pos.col = 2))
print(PlotNumApp, vp = viewport(layout.pos.row = 2,layout.pos.col = 1))
print(PlotFreq, vp = viewport(layout.pos.row = 2,layout.pos.col = 2))
print(PlotMonetary, vp = viewport(layout.pos.row = 3,layout.pos.col = 1))
```
<p>
By looking at recency plot we see that last payments in most recent weeks are more than some weeks ago, which seems to be normal. 
In Tenure plot we see that there is no recent first purchase in our users which could have two meanings:</br>
1- We have covered all possible users and hence we have not new user (Often wrong!)</br>
2- We have a problem in our system to introduce ourself to new users! </br>

Frequency plot gives us a clue that most users install between 35-50 apps from cafe bazaar and paied for 5-15 of them.In Monetary plot we see histogram for users total payments.This plot shows  that most users spend an a total amount between 10000 and 50000 Tomans on different apps during their membership.
It's good to see how users pay for apps in average.
</p>
```{r, echo=FALSE}
avgPayDF <- payments  %>% filter(amount > 0)  %>% group_by(userID)  %>% summarise(count = n(), totalAmount = sum(amount)) %>% 
      mutate(averageAmount = totalAmount %/% count)
quant90Vals <- quantile(avgPayDF$averageAmount, c(0.05,0.95))

avgPlot <- ggplot(avgPayDF, aes(x = averageAmount)) + geom_histogram(binwidth = 500)
avgPlot <- avgPlot + labs(x = 'Average payment (Tomans)', y = 'Count',title = 'Average payments')
avgPlot <- avgPlot + geom_vline(xintercept=quant90Vals,color="red", linetype="dashed", size=1)
print(avgPlot)
```   
<p>
This shows that 90% of users would pay an amount between `r quant90Vals[1]` and `r quant90Vals[2]` Tomans.  
</p>
<p>
_PayRatio_ feature indicates how often users pay in apps.
</p>
```{r}
summary(RFM$PayRatio)
```
<p>By looking to _PayRatio_ summary it tells that mostly 0.2 of apps are get paied.</p>
### User Segmentation
<p>In this part we want to segment users using RFM features. By looking at EDA histograms we can categorize each feature into some intervals. </p>
```{r,echo=FALSE}
RFM_Segs <- data.table(Recency_Week = as.numeric(LastDate - RFM$LastPurchaseDate) %/% 7)
RFM_Segs$Recency <- ordered(ifelse(RFM_Segs$Recency_Week <= 1,"0-1",
                                   ifelse(RFM_Segs$Recency_Week <= 4,"1-4",
                                          ifelse(RFM_Segs$Recency_Week <= 8,"4-8",
                                                 ifelse(RFM_Segs$Recency_Week <= 10,"8-10","10+")))),
                            levels = c('0-1','1-4','4-8','8-10','10+'))

RFM_Segs$Frequency_count <- RFM$NumberofApps
RFM_Segs$Frequency <- ordered(ifelse(RFM_Segs$Frequency_count <= 10,"0-10",
                                     ifelse(RFM_Segs$Frequency_count <= 10-50,"10-50",
                                            ifelse(RFM_Segs$Frequency_count <= 80,"50-80",
                                                   ifelse(RFM_Segs$Frequency_count <= 100,"80-100",
                                                          ifelse(RFM_Segs$Frequency_count <= 110,"100-110","110+"))))),
                              levels = c("0-10","10-50","50-80","80-100","100-110","110+"))
RFM_Segs$Monetary_Value <- RFM$TotalAmount
RFM_Segs$Monetary <- ordered(ifelse(RFM_Segs$Monetary_Value <= 1000,"0-1K",
                                    ifelse(RFM_Segs$Monetary_Value <= 10000,"1K-10K",
                                           ifelse(RFM_Segs$Monetary_Value <= 30000,"10K-30K",
                                                  ifelse(RFM_Segs$Monetary_Value <= 50000,"30K-50K","50K+")))),
                             levels = c("0-1K","1K-10K","10K-50K","10K-30K","30K-50K","50K+"))


RFM_Segs$Tenure_weeks <- as.numeric(LastDate - RFM$FirstPurchaseDate) %/% 7
RFM_Segs$Tenure <- ordered(ifelse(RFM_Segs$Monetary_Value <= 140,"0-140",
                                  ifelse(RFM_Segs$Monetary_Value <= 150,"140-150",
                                         ifelse(RFM_Segs$Monetary_Value <=155,"150-155","155+"))),
                           levels = c("0-140","140-150","150-155","155+"))
```
<p>By doing so we can have an overview of users RFM features</p>
```{r}
summary(select(RFM_Segs,Recency,Frequency,Monetary,Tenure))
```
<p>
In the above table we see that most users have a payement or installation at least in last 4 weeks. This means a little chance to have lost users! </br>
The Frequency confirms that users install 50-80 apps in their membership.</br>
The Monetary shows users total spend statistics (most likely between 10K and 50K Tomans). and the Tenure says we have no new user!
</p>
### Group Recommendations
<p>
In this part we want to cluster users using RFM features and create some plans for customers which can be more involved and more benefitial in our syste,</br>
After cleaning data and get RFM features we use KMeans algorithm to cluster users. As mentioned before some number of clusters have been tested and K=3 selected as most interpretable cluster count.
It's worth mentioning that each of RFM features have been scaled between 0 and 1 to prevent feature range effects.
</p>
```{r, echo=FALSE}
RFM_Values <- select(RFM_Segs,Recency_Week,Frequency_count,Monetary_Value)
# Normalize Data for Clustering
normalVec = function(x){
      (x - min(x)) / (max(x)-min(x))
}

normRFM <- sapply(RFM_Values, FUN = normalVec)
clustRes <- kmeans(normRFM,3)

P2 <- ggplot(RFM_Segs,aes(Recency_Week,Frequency_count))
P2 <- P2 +  geom_point(aes(size = Monetary_Value,colour = factor(clustRes$cluster)),alpha = 0.1)
print(P2)
```
In the above plot color shows user cluster, horizontal axes is Recency, vertical axes is Frequncy and the size of points shows users Monetary.</br>
Let's call users which have high frequency and most recent activities **good users**.
```{r, echo=TRUE}
goodUsers <- RFM$userID[which(clustRes$cluster == 2)]
```
In the plot good users are in green area. </br>
TO suggest some apps to non-good user hoping they install the apps and pay for them we can identify hot apps in green area and suggest them to other users (or any other kind of plans for those apps). </br>
This is done by calculating app-rate average for good users and select top 10 ratings.
After that we have 10 app IDs which can be used for any king of recommendation or promotion planning for non-good users.
```{r, echo=TRUE}
appRates <- colMeans(ratings[goodUsers,],na.rm = TRUE)
top10 <- sort(appRates,decreasing = TRUE, index.return=TRUE)$ix[1:10]
print(top10)
```
<p>
This 10 app IDs are IDs for hot apps in good users cluster. we can recommend them to other users to get more installation and hopefully more payements.</p>
<p>
In the next part we are going to build a per-user recommendation model.
</P>
### Per User Recommendations
<p>
If we have possibility to recommend apps per user, we can use users rating analysis to recommend most probable apps to the users.</br>
One of the most conventional methods is collaborative filtering which is based on calculating user ratings similarity. In this research we use _recommenderLab_ library functions. Good Users (Green Area) are selected as training instances. and again we want to suggest apps to non-good users hoping they install and pay for them. </br>
In the first step we train recommendation model using _UBCF_ algorithm.
</p>
```{r, echo=TRUE}
# Select Good Users for training
trainIndex <- which(clustRes$cluster == 2)
affinityMatrix<- as(ratings,"realRatingMatrix")
# Train UBCF Recommender Model
recModel<-Recommender(affinityMatrix[trainIndex], method = "UBCF")
```
<p>
And then we can predict most likely apps for non-good users using _recModel_.
predict will predict ratings for all apps which have not rate for each user. getting for example top 10 of the apps gives a good list to recommend apps to the user.
</p>
```{r, echo=TRUE}
testIndex <- sample(which(clustRes$cluster != 2),10)
# Testing non-good users
recom <- predict(recModel, affinityMatrix[testIndex,], type="ratings")
recomMat <- as(recom,"matrix")
get10 <- function(x){
      sort(x,decreasing = TRUE, index.return = TRUE)$ix[1:10]
}
# Get top-10 recommendations for each test user
res  <- apply(recomMat, MARGIN = 1, FUN = get10)
resTbl <- data.table(userID = testIndex,res)
print(resTbl)
```
<p>
In the above table each row corresponds to one user and each column is and ID for one of top 10 recommendations for the user.
</p>
# Summary and Results
<p>
In this research we have done some simple analysis and simulated user installations and payments data. After getting and cleaning data we have clustered users to get appropriate recommendation options. Results of this research is listed below:
</p>
<li>Looking at Tenure Plot in EDA shows that we have no new user in our system which means either we
have all possible users or there is a problem with our advertisment system to get new users!</li>
<li> In average 0.2 of installed apps will get paied for each user.</li>
<li> Including in-app purchases which costs more than `r quant90Vals[2]` have very little chance to get paied </li>
<li>We have two recommendation systems now: group based and per-user. we can recommend apps using these two systems to users to get paid more hopefully </li>
